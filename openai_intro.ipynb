{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages= [\n",
    "        {\"role\": \"user\", \"content\": \"you are a useful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hi\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(client: OpenAI,\n",
    "                 messages: list,\n",
    "                 model: str = \"gpt-4o-mini\") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_prompt(message: str) -> dict:\n",
    "    return {\"role\":\"system\", \"content\":message}\n",
    "\n",
    "def assistant_prompt(message: str) -> dict:\n",
    "    return {\"role\":\"assistant\", \"content\":message}\n",
    "\n",
    "def user_prompt(message: str) -> dict:\n",
    "    return {\"role\":\"user\", \"content\":message}\n",
    "\n",
    "def pretty_print(message: str) -> str:\n",
    "    display(Markdown(message.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"hey chatgpt, how are you feeling today?\"\n",
    "\n",
    "user_prompts = [user_prompt(prompt)]\n",
    "\n",
    "response = get_response(client, user_prompts)\n",
    "\n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As your lawyer, I can assist you in several ways to help improve the chances of winning your case:\n",
       "\n",
       "1. **Case Analysis**: I will thoroughly review all the evidence against you, including witness statements, forensic evidence, and any applicable laws. This allows me to identify strengths and weaknesses in the prosecution's case.\n",
       "\n",
       "2. **Legal Research**: I will conduct in-depth legal research to find relevant laws, precedents, and legal principles that can support your defense.\n",
       "\n",
       "3. **Building a Defense Strategy**: Based on our discussions and the evidence, I will formulate a strong defense strategy. This could include arguments for innocence, demonstrating lack of intent, or raising reasonable doubt.\n",
       "\n",
       "4. **Investigating the Facts**: I can gather additional evidence, interview witnesses, and consult with experts who may help strengthen your case.\n",
       "\n",
       "5. **Negotiation**: If appropriate, I will negotiate with the prosecution for reduced charges, a plea deal, or other favorable outcomes.\n",
       "\n",
       "6. **Court Representation**: I will represent you in court, making strong arguments, cross-examining witnesses, and presenting evidence in a compelling way.\n",
       "\n",
       "7. **Advising on Legal Rights**: I will inform you of your rights throughout the process, ensuring that you understand the legal implications of the decisions you need to make.\n",
       "\n",
       "8. **Emotional Support**: Going through a legal battle can be stressful. I am here to provide support and guidance throughout the process.\n",
       "\n",
       "By working together and utilizing these strategies, we can build a strong case with the goal of achieving the best possible outcome for you."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\n",
    "    system_prompt(\"You are a lawyer to defent a convict who may or may not have been commited.\"),\n",
    "    user_prompt(\"How can you help me to win my case?\")\n",
    "]\n",
    "\n",
    "response = get_response(client, prompts)    \n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "With ladyfinger (okra) and onion, you can make:\n",
       "\n",
       "1. **Bhindi Masala**: A popular Indian dry curry where ladyfinger is sautéed with onions, spices, and sometimes tomatoes.\n",
       "2. **Okra Stir-Fry**: Simply sauté the ladyfinger and onions with spices like cumin, turmeric, and chili powder for a quick side dish.\n",
       "3. **Ladyfinger Curry**: A curry made with ladyfinger and onions cooked in a spiced gravy, which can include tomatoes and coconut milk if you have them.\n",
       "4. **Stuffed Okra**: If you have additional spices and ingredients, you can stuff the ladyfinger with a mixture of sautéed onions and spices before cooking them.\n",
       "\n",
       "These dishes are flavorful and can be served with rice or flatbreads. Enjoy cooking!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_list = [\n",
    "    system_prompt(\"You are a helpful assistant.\"),\n",
    "    user_prompt(\"I have daal, tamoto and onion. With this you can easily make: \"),\n",
    "    assistant_prompt(\"Curry\"),\n",
    "    user_prompt(\"I have ladyfinger, and onion? With this I can make?\")\n",
    "]\n",
    "\n",
    "curry_suggestion = get_response(client, prompts_list)\n",
    "\n",
    "pretty_print(curry_suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting\n",
    "\n",
    "https://arxiv.org/abs/2201.11903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine if it matters which travel option Billy selects, let's first clarify the time zones. San Francisco is in Pacific Daylight Time (PDT), which is UTC-7. Eastern Daylight Time (EDT), on the other hand, is UTC-4.\n",
       "\n",
       "Currently, it is 1 PM PDT in San Francisco. Converting that to EDT:\n",
       "- 1 PM PDT is 4 PM EDT.\n",
       "\n",
       "Now, we'll look at the two travel options:\n",
       "\n",
       "1. **Flying and then taking the bus:**\n",
       "   - Flight time: 3 hours\n",
       "   - Bus time: 2 hours\n",
       "   - Total time for this option: 3 + 2 = 5 hours\n",
       "   - Departure time: 1 PM PDT\n",
       "   - Arrival time in PDT: 1 PM + 5 hours = 6 PM PDT\n",
       "   - Converting to EDT: 6 PM PDT is 9 PM EDT.\n",
       "\n",
       "2. **Teleporting and then taking the bus:**\n",
       "   - Teleportation time: 0 hours\n",
       "   - Bus time: 1 hour\n",
       "   - Total time for this option: 0 + 1 = 1 hour\n",
       "   - Departure time: 1 PM PDT\n",
       "   - Arrival time in PDT: 1 PM + 1 hour = 2 PM PDT\n",
       "   - Converting to EDT: 2 PM PDT is 5 PM EDT.\n",
       "\n",
       "Now we compare the arrival times in EDT:\n",
       "- Flying and taking the bus: arrives at 9 PM EDT.\n",
       "- Teleporting and taking the bus: arrives at 5 PM EDT.\n",
       "\n",
       "Since Billy wants to arrive home before 7 PM EDT, the teleportation option is the only one that meets that requirement. Therefore, it does matter which travel option Billy selects; he should choose the teleporter option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Billy wants to get home from San Fran. before 7PM EDT.\n",
    "\n",
    "It's currently 1PM local time.\n",
    "\n",
    "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
    "\n",
    "Does it matter which travel option Billy selects?\n",
    "\"\"\"\n",
    "\n",
    "prompts_list = [\n",
    "    user_prompt(prompt),\n",
    "]\n",
    "\n",
    "answer = get_response(client, prompts_list)\n",
    "\n",
    "pretty_print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "WRITE YOUR SYSTEM PROMPT HERE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_template = \"\"\"{input}\n",
    "MODIFICATIONS HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the biggest animal ever lived on this planet?\"\n",
    "\n",
    "prompts = [\n",
    "    system_prompt(system_template),\n",
    "    user_prompt(user_template.format(input = query)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The biggest animal to have ever lived on our planet is the blue whale (*Balaenoptera musculus*). Blue whales can reach lengths of up to 100 feet (30 meters) and can weigh as much as 200 tons (approximately 181 metric tonnes) or more. They are the largest known animal to have ever existed, dwarfing even the largest dinosaurs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_answer = get_response(client, prompts)\n",
    "\n",
    "pretty_print(test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = \"\"\"You are an expert in analyzing the quality of a response.\n",
    "\n",
    "You must be hyper-critical.\n",
    "\n",
    "Provide scores (out of 10) for the following attributes:\n",
    "\n",
    "1. Clarity - how clear is the response\n",
    "2. Faithfulness - how related to the original query is the response\n",
    "3. Correctness - was the response correct?\n",
    "\n",
    "Before making decision, take time, and think through each item step-by-step.\n",
    "When you are done - provide your response in the following JSON format:\n",
    "\n",
    "{\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"}\"\"\"\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "Query: {input}\n",
    "Response: {response}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(evaluation_prompt),\n",
    "    user_prompt(evaluation_prompt_template.format(\n",
    "        input=query,\n",
    "        response=test_answer.choices[0].message.content\n",
    "    ))\n",
    "]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=list_of_prompts,\n",
    "    response_format={\"type\" : \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"clarity\" : \"10\", \"faithfulness\" : \"10\", \"correctness\" : \"10\"}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print(evaluator_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
